get_all_publications = function(authorid) {
# initializing the publication list
all_publications = NULL
# initializing a counter for the citations
cstart = 0
# initializing a boolean that check if the loop should continue
notstop = TRUE
while (notstop) {
new_publications = try(get_publications(my_id, cstart=cstart), silent=TRUE)
if (class(new_publications)=="try-error") {
notstop = FALSE
} else {
# append publication list
all_publications = rbind(all_publications, new_publications)
cstart=cstart+20
}
}
return(all_publicationss)
}
library(scholar)
install.packages("scholar")
library(scholar)
library(scholar)
my_id = "cQm68jUAAAAJ"
all_publications = get_all_publications(my_id)
get_all_publications = function(authorid) {
# initializing the publication list
all_publications = NULL
# initializing a counter for the citations
cstart = 0
# initializing a boolean that check if the loop should continue
notstop = TRUE
while (notstop) {
new_publications = try(get_publications(my_id, cstart=cstart), silent=TRUE)
if (class(new_publications)=="try-error") {
notstop = FALSE
} else {
# append publication list
all_publications = rbind(all_publications, new_publications)
cstart=cstart+20
}
}
return(all_publications)
}
all_publications = get_all_publications(my_id)
dim(all_publications)
table(all_publications$year)
summary(all_publications$cites)
get_all_coauthors = function(my_id, me=NULL) {
all_publications = get_all_publications(my_id)
if (is.null(me))
me = strsplit(get_profile(my_id)$name, " ")[[1]][2]
# make the author list a character vector
all_authors = sapply(all_publications$author, as.character)
# split it over ", "
all_authors = unlist(sapply(all_authors, strsplit, ", "))
names(all_authors) = NULL
# remove "..." and yourself
all_authors = all_authors[!(all_authors %in% c("..."))]
all_authors = all_authors[-grep(me, all_authors)]
# make a data frame with authors by decreasing number of appearance
all_authors = data.frame(name=factor(all_authors,
levels=names(sort(table(main_authors),decreasing=TRUE))))
}
all_authors = get_all_coauthors(my_id, me="campa")
all_authors = get_all_coauthors(my_id, me="Campa")
get_all_coauthors = function(my_id, me=NULL) {
all_publications = get_all_publications(my_id)
if (is.null(me))
me = strsplit(get_profile(my_id)$name, " ")[[1]][2]
# make the author list a character vector
all_authors = sapply(all_publications$author, as.character)
# split it over ", "
all_authors = unlist(sapply(all_authors, strsplit, ", "))
names(all_authors) = NULL
# remove "..." and yourself
all_authors = all_authors[!(all_authors %in% c("..."))]
all_authors = all_authors[-grep(me, all_authors)]
# make a data frame with authors by decreasing number of appearance
all_authors = data.frame(name=factor(all_authors,
levels=names(sort(table(all_authors),decreasing=TRUE))))
}
all_authors = get_all_coauthors(my_id, me="Campa")
get_all_coauthors = function(my_id, me=NULL) {
all_publications = get_all_publications(my_id)
if (is.null(me))
me = strsplit(get_profile(my_id)$name, " ")[[1]][2]
# make the author list a character vector
all_authors = sapply(all_publications$author, as.character)
# split it over ", "
all_authors = unlist(sapply(all_authors, strsplit, ", "))
names(all_authors) = NULL
# remove "..." and yourself
all_authors = all_authors[!(all_authors %in% c("..."))]
all_authors = all_authors[-grep(me, all_authors)]
# make a data frame with authors by decreasing number of appearance
all_authors = data.frame(name=factor(all_authors,
levels=names(sort(table(main_authors),decreasing=TRUE))))
}
main_authors = all_authors[all_authors$name %in% names(which(table(all_authors$name)>1))]
all_authors
all_authors$name
names(which(table(all_authors$name)>1))
all_authors$name %in% names(which(table(all_authors$name)>1))
all_authors
all_authors[all_authors$name %in% names(which(table(all_authors$name)>1))]
all_authors[,all_authors$name %in% names(which(table(all_authors$name)>1))]
all_authors[all_authors$name %in% names(which(table(all_authors$name)>1)),]
main_authors = all_authors[all_authors$name %in% names(which(table(all_authors$name)>1)),]
library(ggplot2)
p = ggplot(main_authors, aes(x=name) + geom_bar(fill=brewer.pal(3, "Set2")[2]) +
)
p = ggplot(main_authors, aes(x=name)) + geom_bar(fill=brewer.pal(3, "Set2")[2]) +
xlab("co-author") + theme_bw() + theme(axis.text.x = element_text(angle=90, hjust=1))
main_authors
all_authors
main_authors
all_authors$name %in% names(which(table(all_authors$name)>1))
all_authors = get_all_coauthors(my_id, me="Campa")
all_authors
get_abstract = function(pub_id, my_id) {
print(pub_id)
paper_url = paste0("http://scholar.google.com/citations?view_op=view_citation&hl=fr&user=",
my_id, "&citation_for_view=", my_id,":", pub_id)
paper_page = htmlTreeParse(paper_url, useInternalNodes=TRUE, encoding="utf-8")
paper_abstract = xpathSApply(paper_page, "//div[@id='gsc_descr']", xmlValue)
return(paper_abstract)
}
get_abstract = function(pub_id, my_id) {
print(pub_id)
paper_url = paste0("http://scholar.google.com/citations?view_op=view_citation&hl=fr&user=",
my_id, "&citation_for_view=", my_id,":", pub_id)
paper_page = htmlTreeParse(paper_url, useInternalNodes=TRUE, encoding="utf-8")
paper_abstract = xpathSApply(paper_page, "//div[@id='gsc_descr']", xmlValue)
return(paper_abstract)
}
all_abstracts = sapply(all_publications$pubid, get_abstract)
# abstract word analysis
get_all_abstracts = function(my_id) {
all_publications = get_all_publications(my_id)
all_abstracts = sapply(all_publications$pubid, get_abstract)
return(all_abstracts)
}
library(XML)
mu::mu.library("XML")
mu::mu.library(tm)
mu::mu.library("tm")
library("XML")
all_abstracts = get_all_abstracts(my_id)
library("tm")
all_abstracts = get_all_abstracts(my_id = my_id)
# abstract word analysis
get_all_abstracts = function(author_id) {
all_publications = get_all_publications(author_id)
all_abstracts = sapply(all_publications$pubid, get_abstract)
return(all_abstracts)
}
all_abstracts = get_all_abstracts(my_id = my_id)
all_abstracts = get_all_abstracts(my_id)
get_abstract = function(pub_id, my_id) {
print(pub_id)
paper_url = paste0("http://scholar.google.com/citations?view_op=view_citation&hl=fr&user=",
my_id, "&citation_for_view=", my_id,":", pub_id)
paper_page = htmlTreeParse(paper_url, useInternalNodes=TRUE, encoding="utf-8")
paper_abstract = xpathSApply(paper_page, "//div[@id='gsc_descr']", xmlValue)
return(paper_abstract)
}
return(all_abstracts)
# abstract word analysis
get_all_abstracts = function(author_id) {
all_publications = get_all_publications(author_id)
all_abstracts = sapply(all_publications$pubid, get_abstract)
return(all_abstracts)
}
library("XML")
all_abstracts = get_all_abstracts(my_id)
get_abstract = function(pub_id, my_id) {
print(pub_id)
authord_id <- my_id
paper_url = paste0("http://scholar.google.com/citations?view_op=view_citation&hl=fr&user=",
authord_id, "&citation_for_view=", authord_id,":", pub_id)
paper_page = htmlTreeParse(paper_url, useInternalNodes=TRUE, encoding="utf-8")
paper_abstract = xpathSApply(paper_page, "//div[@id='gsc_descr']", xmlValue)
return(paper_abstract)
}
all_abstracts = get_all_abstracts(my_id)
# abstract word analysis
get_all_abstracts = function(author_id) {
all_publications = get_all_publications(author_id)
all_abstracts = sapply(all_publications$pubid, author_id, get_abstract)
return(all_abstracts)
}
library("XML")
all_abstracts = get_all_abstracts(my_id)
get_abstract = function(pub_id, authord_id) {
print(pub_id)
paper_url = paste0("http://scholar.google.com/citations?view_op=view_citation&hl=fr&user=",
authord_id, "&citation_for_view=", authord_id,":", pub_id)
paper_page = htmlTreeParse(paper_url, useInternalNodes=TRUE, encoding="utf-8")
paper_abstract = xpathSApply(paper_page, "//div[@id='gsc_descr']", xmlValue)
return(paper_abstract)
}
all_abstracts = get_all_abstracts(my_id)
# abstract word analysis
get_all_abstracts = function(author_id) {
all_publications = get_all_publications(author_id)
all_abstracts = sapply(all_publications$pubid, get_abstract)
return(all_abstracts)
}
library("XML")
all_abstracts = get_all_abstracts(my_id)
# abstract word analysis
get_all_abstracts = function(author_id) {
all_publications = get_all_publications(author_id)
all_abstracts = sapply(list(all_publications$pubid, author_id), get_abstract)
return(all_abstracts)
}
library("XML")
all_abstracts = get_all_abstracts(my_id)
get_abstract = function(pub_id, author_id) {
print(pub_id)
paper_url = paste0("http://scholar.google.com/citations?view_op=view_citation&hl=fr&user=",
author_id, "&citation_for_view=", author_id,":", pub_id)
paper_page = htmlTreeParse(paper_url, useInternalNodes=TRUE, encoding="utf-8")
paper_abstract = xpathSApply(paper_page, "//div[@id='gsc_descr']", xmlValue)
return(paper_abstract)
}
all_abstracts = get_all_abstracts(my_id)
get_abstract = function(pub_id, author_id) {
print(pub_id)
id <- author_id
paper_url = paste0("http://scholar.google.com/citations?view_op=view_citation&hl=fr&user=",
id, "&citation_for_view=", id,":", pub_id)
paper_page = htmlTreeParse(paper_url, useInternalNodes=TRUE, encoding="utf-8")
paper_abstract = xpathSApply(paper_page, "//div[@id='gsc_descr']", xmlValue)
return(paper_abstract)
}
all_abstracts = get_all_abstracts(my_id)
# abstract word analysis
get_all_abstracts = function(author_id) {
all_publications = get_all_publications(author_id)
all_abstracts = sapply(all_publications$pubid, get_abstract)
return(all_abstracts)
}
library("XML")
all_abstracts = get_all_abstracts(my_id)
get_abstract = function(pub_id, author_id) {
print(pub_id)
id <<- author_id
paper_url = paste0("http://scholar.google.com/citations?view_op=view_citation&hl=fr&user=",
id, "&citation_for_view=", id,":", pub_id)
paper_page = htmlTreeParse(paper_url, useInternalNodes=TRUE, encoding="utf-8")
paper_abstract = xpathSApply(paper_page, "//div[@id='gsc_descr']", xmlValue)
return(paper_abstract)
}
all_abstracts = get_all_abstracts(my_id)
all_abstracts
all_publications
get_abstract(all_publications)
get_abstract(all_publications, my_id)
all_publications
get_abstract(all_publications[1,], my_id)
get_abstract(all_publications[1,], my_id)
all_publications[1,]
pub_id <- all_publications[1,]
pub_id <- all_publications[1,]$pubid
print(pub_id)
paper_url = paste0("http://scholar.google.com/citations?view_op=view_citation&hl=fr&user=",
author_id, "&citation_for_view=", author_id,":", pub_id)
author_id <- my_id
paper_url = paste0("http://scholar.google.com/citations?view_op=view_citation&hl=fr&user=",
author_id, "&citation_for_view=", author_id,":", pub_id)
paper_url
paper_page = htmlTreeParse(paper_url, useInternalNodes=TRUE, encoding="utf-8")
devtools::install_github("amcrisan/Adjutant")
library(adjutant)
runAdjutant()
devtools::install_github("amcrisan/Adjutant")
library(adjutant)
runAdjutant()
runAdjutant()
library(adjutant)
runAdjutant()
devtools::install_github("amcrisan/Adjutant")
library(adjutant)
runAdjutant()
library(adjutant)
library(dplyr)
library(ggplot2)
library(tidytext) #for stop words
#also set a seed - there is some randomness in the analysis.
set.seed(416)
df<-processSearch("(outbreak OR epidemic OR pandemic) AND genom*",retmax=2000)
##
tidy_df<-tidyCorpus(corpus = df)
df
##
df<-processSearch("(outbreak OR epidemic OR pandemic) AND genom*",retmax=200)
runAdjutant()
library(scholar)
# Define the id for Richard Feynman
id <- 'B7vSqZsAAAAJ'
# Get his profile and print his name
l <- get_profile(id)
l$name
l
# Get his citation history, i.e. citations to his work in a given year
get_citation_history(id)
# Get his publications (a large data frame)
get_publications(id)
